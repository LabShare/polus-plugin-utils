{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: itkwidgets 0.22.0 has requirement itk-meshtopolydata>=0.5.1, but you'll have itk-meshtopolydata 0.3.4 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the lines below to install the required dependencies. \n",
    "#!pip install opencv_python_headless==4.1.2.30 --exists-action i -q\n",
    "#!pip install git+https://github.com/AllenInstitute/aics-segmentation@d1c666b26e901cbe6d7c74f57eafefa5af9443a5 --exists-action i -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The notebook consits of two parts, both in different cells.\n",
    "\n",
    "Cell 1 : \n",
    "\n",
    "Author: Nick Schaub (nick.schaub@nih.gov)\n",
    "\n",
    "Description: This cell contains WippPy which consists of classes for interacting with WIPP.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import json as json_lib\n",
    "import requests, copy, re\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Initialize the loggercli\n",
    "logging.basicConfig(format='%(asctime)s - %(name)-8s - %(levelname)-8s - %(message)s',\n",
    "                    datefmt='%d-%b-%y %H:%M:%S')\n",
    "logger = logging.getLogger(\"wipp\")\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Initialize the WippData Class\n",
    "class WippData(object):\n",
    "    \"\"\" Wipp data superclass\n",
    "    \n",
    "    This class should be implemented by all Wipp data type classes.\n",
    "    \n",
    "    \"\"\"\n",
    "    _entry_point = None\n",
    "    _data_type_name = None\n",
    "    api_route = 'http://wipp-ui.ci.aws.labshare.org/api/'\n",
    "    _headers = {'Content-Type': 'application/json'}\n",
    "    _logger = logging.getLogger('wipp.Data')\n",
    "    \n",
    "    def __init__(self,name=None,create=False,json=None,api_route=None,**kwargs):\n",
    "        if api_route != None:\n",
    "            self._logger.info('api_route: {}'.format(api_route))\n",
    "            self.api_route = api_route\n",
    "        if create and name != None:\n",
    "            self._logger.info('create(): {}'.format(name))\n",
    "            kwargs['data'] = {'name': name}\n",
    "            self.json = self.create(**kwargs)\n",
    "        elif 'data' in kwargs:\n",
    "            self._logger.info('create(): attempting to create instance of {}'.format(self.__class__.__name__))\n",
    "            self.json = self.create(**kwargs)\n",
    "        elif json:\n",
    "            self._logger.debug('creating object using json')\n",
    "            self.json = json\n",
    "        else:\n",
    "            self.json = self._get(**kwargs)\n",
    "    \n",
    "        if self.json!=None:\n",
    "            for key,value in self.json.items():\n",
    "                self._logger.debug('setattr(): {}={}')\n",
    "                setattr(self,key,value)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{self.name} (id: {self.id})'\n",
    "    \n",
    "    def delete(self):\n",
    "        self._logger.info('delete(): {}'.format(self.api_route + self._entry_point + '/' + self.id))\n",
    "        requests.delete(self.api_route + self._entry_point + '/' + self.id)\n",
    "        \n",
    "    def create(self,**kwargs):\n",
    "        self._logger.info('create(): {}'.format(self.api_route + self._entry_point))\n",
    "        return self._post(**kwargs)\n",
    "        \n",
    "    def _post(self,**kwargs):\n",
    "        self._logger.debug('_post(): endpoint={}'.format(self.api_route + self._entry_point))\n",
    "        \n",
    "        config = {key:value for key,value in kwargs.items() if key in ['params','headers']}\n",
    "        if 'data' in kwargs:\n",
    "            config['data'] = json_lib.dumps(kwargs['data'])\n",
    "        if 'headers' not in config.keys():\n",
    "            config['headers'] = self._headers\n",
    "        \n",
    "        for key,val in config.items():\n",
    "            self._logger.debug('_post(): {}={}'.format(key,val))\n",
    "        \n",
    "        if 'entrypoint' not in kwargs.keys():\n",
    "            entrypoint = self._entry_point\n",
    "        else:\n",
    "            entrypoint = kwargs['entrypoint']\n",
    "            \n",
    "        r = requests.post(self.api_route + entrypoint,**config)\n",
    "        self._logger.debug('_post(): status_code={}'.format(r.status_code))\n",
    "        if r.status_code==201 or r.status_code==200:\n",
    "            return r.json()\n",
    "        elif r.status_code==409:\n",
    "            self._logger.warning('_post(): Plugin already exists.')\n",
    "        else:\n",
    "            self._logger.critical('_post(): message={}'.format(r.text),exc_info=True)\n",
    "            raise ValueError(self.__class__.__name__ + ' Error (status code {}): {}'.format(r.status_code,r.text))\n",
    "        \n",
    "    def _get(self,entrypoint=None,**kwargs):\n",
    "        if entrypoint==None:\n",
    "            entrypoint=self._entry_point\n",
    "        self._logger.debug('_get(): endpoint={}'.format(self.api_route + entrypoint))\n",
    "        \n",
    "        config = {key:value for key,value in kwargs.items() if key in ['params','headers','data']}\n",
    "        if 'data' in kwargs:\n",
    "            config['data'] = json_lib.dumps(kwargs['data'])\n",
    "        if 'headers' not in config.keys():\n",
    "            config['headers'] = self._headers\n",
    "        \n",
    "        for key,val in config.items():\n",
    "            self._logger.debug('_get(): {}={}'.format(key,val))\n",
    "        \n",
    "        r = requests.get(self.api_route + entrypoint,**config)\n",
    "        self._logger.debug('_get(): status_code={}'.format(r.status_code))\n",
    "        if r.status_code==200:\n",
    "            return r.json()\n",
    "        else:\n",
    "            self._logger.critical('_get(): message={}'.format(r.text))\n",
    "            raise ValueError(self.__class__.__name__ + ' Error (status code {}): {}'.format(r.status_code,r.text))\n",
    "            \n",
    "    @classmethod\n",
    "    def setWippUrl(cls,url):\n",
    "        cls._logger.info('setWippUrl(): {}'.format(url))\n",
    "        cls.api_route = url\n",
    "            \n",
    "    @classmethod\n",
    "    def all(cls,entry_point=False):\n",
    "        \"\"\"Get all instances of a data type\n",
    "\n",
    "        Args:\n",
    "            cls: Class reference for handling a WIPP data type\n",
    "            entry_point: API entry point, appended to api path\n",
    "\n",
    "        Returns:\n",
    "            A dictionary, where the keys are hashes referencing a data\n",
    "            instance and values are data_class objects.\n",
    "        \"\"\"\n",
    "        if not entry_point:\n",
    "            entry_point = cls._entry_point\n",
    "        cls._logger.info('all(): getting all instances...')\n",
    "        page = 0\n",
    "        numel = 1000\n",
    "        r = requests.get(cls.api_route + entry_point,params={'page':page,'size':numel})\n",
    "        if r.status_code==200:\n",
    "            all_data = r.json()['_embedded'][cls._entry_point]\n",
    "            data = {}\n",
    "            for datum in all_data:\n",
    "                data[datum['id']] = cls(json=datum)\n",
    "                cls._logger.debug('all(): object={}'.format(data[datum['id']]))\n",
    "            for i in range(r.json()['page']['totalPages']-1):\n",
    "                page += 1\n",
    "                r = requests.get(cls.api_route + entry_point,params={'page':page,'size':numel})\n",
    "                if r.status_code==200:\n",
    "                    all_data = r.json()['_embedded'][cls._entry_point]\n",
    "                    data = {}\n",
    "                    for datum in all_data:\n",
    "                        data[datum['id']] = cls(json=datum)\n",
    "                        cls._logger.debug('all(): object={}'.format(data[datum['id']]))\n",
    "        else:\n",
    "            data = {}\n",
    "        return data\n",
    "    \n",
    "    @classmethod\n",
    "    def get_by_id(cls,oid):\n",
    "        \"\"\"Get data by id\n",
    "\n",
    "        Args:\n",
    "            cls: Class reference for handling a WIPP data type\n",
    "            oid: Hash reference of data to access\n",
    "\n",
    "        Returns:\n",
    "            An object of type cls\n",
    "        \"\"\"    \n",
    "        cls._logger.debug('get_by_id(): oid={}'.format(oid))\n",
    "        r = requests.get(cls.api_route + cls._entry_point + '/' + oid)\n",
    "        if r.status_code==200:\n",
    "            instance = cls(json=r.json())\n",
    "        else:\n",
    "            cls._logger.warning('get_by_id(): returning NoneType')\n",
    "            instance = None\n",
    "        return instance\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_name(dtype,value):\n",
    "        \"\"\" Get the name of a data instance\n",
    "\n",
    "        Args:\n",
    "            dtype: WIPP data type\n",
    "            value: Unique hash reference\n",
    "\n",
    "        Returns:\n",
    "            A string containing the human readable dataset name\n",
    "        \"\"\"\n",
    "        for cls in WippData.__subclasses__():\n",
    "            if dtype==cls._entry_point:\n",
    "                cls._logger.debug('get_name(): finding object associated with id={}'.format(value))\n",
    "                return cls.all()[value].name\n",
    "    \n",
    "class WippJob(WippData):\n",
    "    \"\"\" Class to handle WIPP Jobs\n",
    "\n",
    "    Attributes:\n",
    "        name: the name given to the WIPP job\n",
    "        id: a unique hash assigned to the WIPP job\n",
    "        json: The raw json returned by the WIPP Job backend query\n",
    "        status: execution status of the WIPP job\n",
    "        plugin_id: a unique hash assigned to the plugin used by the WIPP job\n",
    "        plugin_name: the name of the WIPP plugin executed by the job\n",
    "        inputs: the plugin input keys and values for the job\n",
    "        outputs: the plugin output keys and values for the job\n",
    "\n",
    "    Class Methods:\n",
    "        get_all(): Returns a dictionary of all jobs {job hash: WippJob object}\n",
    "        get(jid): Returns job with hash equal to jid\n",
    "\n",
    "    Object Methods:\n",
    "        delete(): Delete the job from WIPP.\n",
    "        create(): Create the job in WIPP.\n",
    "    \"\"\"\n",
    "    _entry_point = 'jobs'\n",
    "    _data_type_name = 'Job'\n",
    "    _logger = logging.getLogger('wipp.Data.WippJob')\n",
    "\n",
    "    # Job template\n",
    "    _payload = {'name': '',            # name of job\n",
    "                'wippExecutable': '',  # plugin id\n",
    "                'type': '',            # name of the plugin\n",
    "                'dependencies': [],    # job ids for dependencies\n",
    "                'parameters': {},      # dictionary of parameters\n",
    "                'outputParameters': {},# dictionary of output parameters\n",
    "                'wippWorkflow': ''}    # wipp workflow id\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{self.name} (id: {self.id})'\n",
    "    \n",
    "class WippWorkflow(WippData):\n",
    "    \"\"\" Class to handle WIPP Workflows\n",
    "\n",
    "    Attributes:\n",
    "        name: the name given to the WIPP workflow\n",
    "        id: a unique hash assigned to the WIPP workflow\n",
    "        json: the raw json returned by the WIPP Workflow backend query\n",
    "        status: the execution status of the workflow\n",
    "        link: a url to the backend workflow json\n",
    "    \n",
    "    Class Methods:\n",
    "        get_all(): Returns a dictionary of all workflows{workflow hash: WippWorkflow object}\n",
    "        get(wid): Returns workflow with hash equal to wid\n",
    "    \n",
    "    Object Methods:\n",
    "        delete(): Delete the workflow from WIPP.\n",
    "        create(): Create the workflow in WIPP.\n",
    "        jobs(): Returns dictionary of all jobs in workflow, {job hash: WippJob object}\n",
    "    \"\"\"\n",
    "    _entry_point = 'workflows'\n",
    "    _data_type_name = 'Workflow'\n",
    "    _logger = logging.getLogger('wipp.Data.WippWorkflow')\n",
    "    \n",
    "    def jobs(self):\n",
    "        self._logger.info('jobs(): Getting all jobs for workflow={}'.format(self.id))\n",
    "        if self.id not in WippWorkflow.all().keys():\n",
    "            self._logger.critical('jobs(): Could not find workflow jobs')\n",
    "            raise KeyError('Invalid workflow id.')\n",
    "        \n",
    "        r = self._get(entrypoint='jobs/search/findByWippWorkflow?wippWorkflow='+self.id)\n",
    "        \n",
    "        jobs = {job_json['id']:WippJob(json=job_json) for job_json in r['_embedded']['jobs']}\n",
    "        for job in jobs.values():\n",
    "            self._logger.debug('jobs(): job='.format(job))\n",
    "            \n",
    "        return jobs\n",
    "    \n",
    "    def update(self):\n",
    "        self._logger.info('update(): updating workflow - {}'.format(self.name))\n",
    "        wf = WippWorkflow.get_by_id(self.id)\n",
    "        for key,value in wf.json.items():\n",
    "            setattr(self,key,value)\n",
    "    \n",
    "    def submit(self):\n",
    "        self._post(entrypoint='workflows/' + self.id + '/submit',parameters={'wippWorkflow': self.id})\n",
    "    \n",
    "    def add_job(self,plugin_name,job_name,inputs,plugin_version=None):\n",
    "        payload = copy.deepcopy(WippJob._payload)\n",
    "        plugin = WippPlugin.get_by_name(plugin_name,plugin_version)\n",
    "        dependency_pattern = r'\\{\\{ (.*)\\.(.*) \\}\\}'\n",
    "        self._logger.info('add_job(): job_name={}, plugin_name={}, plugin_version={}'.format(job_name,plugin_name,plugin_version))\n",
    "        \n",
    "        # Add basic info to the payload\n",
    "        payload['name'] = job_name\n",
    "        payload['wippExecutable'] = plugin.id\n",
    "        payload['type'] = plugin.name\n",
    "        payload['wippWorkflow'] = self.id\n",
    "        \n",
    "        # validate and set inputs\n",
    "        for inp in plugin.inputs:\n",
    "            if inp['name'] not in inputs.keys() and inp['required']:\n",
    "                self._logger.critical('add_job(): Missing input {} for plugin {}'.format(inp['name'],plugin.name))\n",
    "            elif inp['name'] not in inputs.keys():\n",
    "                continue\n",
    "            self._logger.debug('add_job(): {}={}'.format(inp['name'],inputs[inp['name']]))\n",
    "            payload['parameters'][inp['name']] = inputs[inp['name']]\n",
    "            \n",
    "            # If input has {{ }}, then it has a dependency\n",
    "            if isinstance(inputs[inp['name']],str):\n",
    "                dependency = re.match(dependency_pattern,inputs[inp['name']])\n",
    "                if dependency != None:\n",
    "                    self._logger.info('add_job(): adding dependency {}'.format(dependency.groups()[0]))\n",
    "                    payload['dependencies'].append(dependency.groups()[0])\n",
    "        \n",
    "        job = WippJob(data=payload)\n",
    "        \n",
    "        return job\n",
    "\n",
    "class WippImageCollection(WippData):\n",
    "    \"\"\" Class to handle WIPP Image Collections\n",
    "\n",
    "    Attributes:\n",
    "        name: the name given to the WIPP Image Collection\n",
    "        id: a unique hash assigned to the WIPP Image Collection\n",
    "        json: the raw json returned by the WIPP Workflow backend query\n",
    "    \n",
    "    Class Methods:\n",
    "        get_all(): Returns a dictionary of all image collections, {image collection hash: WippImageCollection object}\n",
    "        get(icid): Returns image collection with hash equal to icid\n",
    "        get_by_name(ic_name): Returns the first result of a search of image collections matching ic_name\n",
    "    \n",
    "    Object Methods:\n",
    "        create(): Create the workflow in WIPP.\n",
    "        images(): Return a list of dictionaries containing information on every image in the collection\n",
    "    \"\"\"\n",
    "    _entry_point = 'imagesCollections'\n",
    "    _data_type_name = 'Image Collection'\n",
    "    _images = []\n",
    "    _logger = logging.getLogger('wipp.Data.WippImageCollection')\n",
    "    \n",
    "    def delete(self):\n",
    "        \"\"\" Throw an error only if image collection is locked\"\"\"\n",
    "        self._logger.info('delete(): deleting image collection - {}'.format(self.name))\n",
    "        if self.locked:\n",
    "            self._logger.critical('delete(): Cannot delete locked image collection.')\n",
    "            raise PermissionError('Cannot delete locked image collection.')\n",
    "        else:\n",
    "            super().delete()\n",
    "    \n",
    "    @classmethod\n",
    "    def get_by_name(cls,ic_name):\n",
    "        cls._logger.info('get_by_name(): getting image collection - {}'.format(ic_name))\n",
    "        r = requests.get(cls.api_route + cls._entry_point + '/search/findByName',params={'name':ic_name})\n",
    "        cls._logger.debug('get_by_name(): status_code={}'.format(r.status_code))\n",
    "        if r.status_code==200:\n",
    "            imageCollection = cls(json=r.json()['_embedded'][cls._entry_point][0])\n",
    "        else:\n",
    "            imageCollection = []\n",
    "        return imageCollection\n",
    "    \n",
    "    def update(self):\n",
    "        self._logger.info('update(): updating image collection - {}'.format(self.name))\n",
    "        ic = WippImageCollection.get_by_name(self.name)\n",
    "        for key,value in ic.json.items():\n",
    "            setattr(self,key,value)\n",
    "\n",
    "    def add_image(self,file_path):\n",
    "        self._logger.info('add_image(): file_path={}'.format(file_path))\n",
    "        if self.locked:\n",
    "            self._logger.info('add_image(): cannot add image to locked collection')\n",
    "            raise PermissionError('Cannot add images to locked collection.')\n",
    "        if not isinstance(file_path,Path):\n",
    "            file_path = Path(file_path)\n",
    "        return WippImage(self.id,file_path)\n",
    "    \n",
    "    def lock(self):\n",
    "        self._logger.info('lock(): locking imaging collection - {}'.format(self.name))\n",
    "        r = requests.patch(self.api_route + self._entry_point + '/' + self.id,\n",
    "                           headers={'Content-Type': 'application/json'},\n",
    "                           data=json_lib.dumps({'locked': True}))\n",
    "        self._logger.debug('lock(): status_code={}'.format(r.status_code))\n",
    "        \n",
    "    def images(self):\n",
    "        self._logger.info('images(): getting all images for image collection - {}'.format(self.name))\n",
    "        if len(self._images) > 0 and self.locked:\n",
    "            return self._images\n",
    "        page = 0\n",
    "        numel = 1000\n",
    "        images = []\n",
    "        r = self._get(entrypoint=self._entry_point + '/' + self.id + '/images',\n",
    "                      params={'page':page,'size':numel})\n",
    "        if '_embedded' not in r.keys():\n",
    "            return images\n",
    "        \n",
    "        images = r['_embedded']['images']\n",
    "        \n",
    "        for i in range(r['page']['totalPages']-1):\n",
    "            page += 1\n",
    "            r = requests._get(self.api_route + self._entry_point + '/' + self.id + '/images',\n",
    "                              params={'page':page,'size':numel})\n",
    "            images.extend(r['_embedded']['images'])\n",
    "        self._images = images\n",
    "        return images\n",
    "    \n",
    "class WippCsvCollection(WippData):\n",
    "    \"\"\" Class to handle WIPP Csv Collections\n",
    "\n",
    "    Attributes:\n",
    "        name: the name given to the WIPP csv collection\n",
    "        id: a unique hash assigned to the WIPP csv collection\n",
    "        json: the raw json returned by the WIPP csv collection backend query\n",
    "        \n",
    "    Class Methods:\n",
    "        all(): Returns a dictionary of all csv collections, {csv collection hash: WippCsvCollection object}\n",
    "    \n",
    "    Object Methods:\n",
    "        delete(): Delete the csv collection from WIPP.\n",
    "        create(): Create the csv collection in WIPP.\n",
    "    \"\"\"\n",
    "    _entry_point = 'csvCollections'\n",
    "    _data_type_name = 'CSV Collection'\n",
    "    _logger = logging.getLogger('wipp.Data.WippCsvCollection')\n",
    "    \n",
    "class WippNotebook(WippData):\n",
    "    \"\"\" Class to handle WIPP Notebook\n",
    "\n",
    "    Attributes:\n",
    "        name: the name given to the WIPP notebook\n",
    "        id: a unique hash assigned to the WIPP notebook\n",
    "        json: the raw json returned by the WIPP notebook backend query\n",
    "        \n",
    "    Class Methods:\n",
    "        all(): Returns a dictionary of all notebooks, {notebook hash: WippNotebook object}\n",
    "    \n",
    "    Object Methods:\n",
    "        delete(): Delete the notebook from WIPP.\n",
    "        create(): Create the notebook in WIPP.\n",
    "    \"\"\"\n",
    "    _entry_point = 'notebooks'\n",
    "    _data_type_name = 'Notebook'\n",
    "    _logger = logging.getLogger('wipp.Data.WippNotebook')\n",
    "\n",
    "class WippStitchingVector(WippData):\n",
    "    \"\"\" Class to handle WIPP Stitching Vectors\n",
    "\n",
    "    Attributes:\n",
    "        name: the name given to the WIPP stitching vector\n",
    "        id: a unique hash assigned to the WIPP stitching vector\n",
    "        json: the raw json returned by the WIPP stitching vector backend query\n",
    "    \n",
    "    Class methods:\n",
    "        all(): Returns a dictionary of all stitching vectors, {stitching vector hash: WippStitchingVector object}\n",
    "        \n",
    "    Object Methods:\n",
    "        delete(): Delete the stitching vector from WIPP.\n",
    "        create(): Create the stitching vector in WIPP.\n",
    "    \"\"\"\n",
    "    _entry_point = 'stitchingVectors'\n",
    "    _data_type_name = 'Stitching Vector'\n",
    "    _logger = logging.getLogger('wipp.Data.WippStitchingVector')\n",
    "\n",
    "class WippPyramid(WippData):\n",
    "    \"\"\" Class to handle WIPP Pyramid\n",
    "\n",
    "    Attributes:\n",
    "        name: the name given to the WIPP pyramid\n",
    "        id: a unique hash assigned to the WIPP pyramid\n",
    "        json: the raw json returned by the WIPP pyramid backend query\n",
    "    \n",
    "    Class Methods:\n",
    "        all(): Returns a dictionary of all pyramids, {pyramid hash: WippPyramid object}\n",
    "        \n",
    "    Object Methods:\n",
    "        delete(): Delete the pyramid from WIPP.\n",
    "        create(): Create the pyramid in WIPP.\n",
    "    \"\"\"\n",
    "    _entry_point = 'pyramids'\n",
    "    _data_type_name = 'Image Pyramid'\n",
    "    _logger = logging.getLogger('wipp.Data.WippPyramid')\n",
    "\n",
    "class WippImage(object):\n",
    "    \"\"\" Class to handle WIPP Images\n",
    "\n",
    "    Unlike most other WIPP classes, the WippImage class acts very differently from the\n",
    "    other data types. Part of this comes from images being a child of an image collection\n",
    "    and therefore necessitates attachment to a WippImageCollection id.\n",
    "\n",
    "    In general, the best way to instantiate this class is through an WippImageCollection\n",
    "    object using either the images() method to get all images in a collection or the\n",
    "    add_image() method to prepare an image to upload to an unlocked collection.\n",
    "\n",
    "    Attributes:\n",
    "        To be determined\n",
    "    \n",
    "    Class Methods:\n",
    "        To be determined\n",
    "    \n",
    "    Object Methods:\n",
    "        delete(): Delete the image from an unlocked collection in WIPP.\n",
    "        send(): Send the image to WIPP.\n",
    "    \"\"\"\n",
    "    _entry_point = 'imagesCollections/{}/images'\n",
    "    _data_type_name = 'Image'\n",
    "    _flowChunkSize = 1048576\n",
    "    _logger = logging.getLogger('wipp.Data.WippImage')\n",
    "\n",
    "    def __init__(self,ic_id,file_path):\n",
    "        self._entry_point = WippData.api_route + self._entry_point.format(ic_id)\n",
    "        self.file_path = Path(file_path)\n",
    "        if not self.file_path.is_file():\n",
    "            self._logger.critical('__init__(): could not find file - {}'.format(str(self.file_path.absolute())))\n",
    "            raise FileNotFoundError('Could not find file: {}'.format(str(self.file_path.absolute())))\n",
    "\n",
    "        with open(self.file_path,'rb') as in_file:\n",
    "            in_file.seek(0,2)\n",
    "            self._flowTotalSize = in_file.tell()\n",
    "            self._flowTotalChunks = self._flowTotalSize//self._flowChunkSize\n",
    "        \n",
    "        self._flowFilename = self.file_path.name\n",
    "\n",
    "        self.params = {'flowChunkNumber': 1,\n",
    "                       'flowChunkSize': self._flowChunkSize,\n",
    "                       'flowCurrentChunkSize': self._flowChunkSize,\n",
    "                       'flowTotalSize': self._flowTotalSize,\n",
    "                       'flowIdentifier': str(self._flowTotalSize) + '-' + self.file_path.name.replace('.',''),\n",
    "                       'flowFilename': self.file_path.name,\n",
    "                       'flowRelativePath': self.file_path.name,\n",
    "                       'flowTotalChunks': self._flowTotalChunks}\n",
    "        \n",
    "        for key,val in self.params.items():\n",
    "            self._logger.debug('__init__(): {}={}'.format(key,val))\n",
    "        \n",
    "    def get_name(self):\n",
    "        self._logger.info('get_name(): name={}'.format(self.file_path.name))\n",
    "        return self.file_path.name\n",
    "        \n",
    "    def set_name(self,name):\n",
    "        self._logger.info('set_name(): name={}'.format(name))\n",
    "        suffix = ''.join(self.file_path.suffixes)\n",
    "        name = name.split('.')[0] + suffix\n",
    "        self.params['flowIdentifier'] = str(self._flowTotalSize) + '-' + name.replace('.','')\n",
    "        self._logger.debug('set_name(): flowIdentifier={}'.format(self.params['flowIdentifier']))\n",
    "        self.params['flowFilename'] = name\n",
    "        self._logger.debug('set_name(): flowFilename={}'.format(self.params['flowFilename']))\n",
    "        self.params['flowRelativePath'] = name\n",
    "        self._logger.debug('set_name(): flowRelativePath={}'.format(self.params['flowRelativePath']))\n",
    "        \n",
    "    def send(self):\n",
    "        self._logger.info('send(): file={}'.format(self.file_path))\n",
    "        with open(self.file_path,'rb') as in_file:\n",
    "            for chunk in range(1,self._flowTotalChunks):\n",
    "                self._logger.debug('send(): sending chunk {} of {} for file {}'.format(chunk,self._flowTotalChunks,self.file_path))\n",
    "                self.params['flowChunkNumber'] = chunk\n",
    "                for retry in range(0,10):\n",
    "                    try:\n",
    "                        r = requests.post(self._entry_point,\n",
    "                                        params=self.params,\n",
    "                                        headers={'Content-Type': 'image/tiff'},\n",
    "                                        data=in_file.read(1048576))\n",
    "                        break\n",
    "                    except:\n",
    "                        if retry==9:\n",
    "                            print('{}: Reached max tries.'.format(self.params['flowFilename']))\n",
    "                            raise\n",
    "                        print('{}: There was an upload error, will retry in 3 seconds (try {})'.format(self.params['flowFilename'],retry+1))\n",
    "                        in_file.seek(-1048576,1)\n",
    "                        time.sleep(3)\n",
    "            self.params['flowChunkNumber'] = self._flowTotalChunks\n",
    "            self.params['flowCurrentChunkSize'] = self._flowTotalSize-in_file.tell()\n",
    "            self._logger.debug('send(): sending chunk {} of {} for file {}'.format(self._flowTotalChunks,self._flowTotalChunks,self.file_path))\n",
    "            r = requests.post(self._entry_point,\n",
    "                              params=self.params,\n",
    "                              headers={'Content-Type': 'image/tiff'},\n",
    "                              data=in_file.read(self._flowTotalSize-in_file.tell()))\n",
    "\n",
    "class WippTensorflowModel(WippData):\n",
    "    \"\"\" Class to handle WIPP Tensorflow Models\n",
    "\n",
    "    Attributes:\n",
    "        name: the name given to the WIPP tensorflow model\n",
    "        id: a unique hash assigned to the WIPP tensorflow model\n",
    "        json: the raw json returned by the WIPP tensorflow model backend query\n",
    "    \n",
    "    Class Methods:\n",
    "        all(): Returns a dictionary of all models, {tensorflow model hash: WippTensorflowModel object}\n",
    "    \n",
    "    Object Methods:\n",
    "        delete(): Delete the tensorflow model from WIPP.\n",
    "        create(): Create the tensorflow model in WIPP.\n",
    "    \"\"\"\n",
    "    _entry_point = 'tesorflowModels'\n",
    "    _data_type_name = 'Tensorflow Models'\n",
    "    _logger = logging.getLogger('wipp.Data.WippTensorflowModel')\n",
    "        \n",
    "class WippPlugin(WippData):\n",
    "    \"\"\" Class to handle WIPP Plugins\n",
    "\n",
    "    Attributes:\n",
    "        name: the name given to the WIPP plugin\n",
    "        id: a unique hash assigned to the WIPP plugin\n",
    "        json: the raw json returned by the WIPP plugin backend query\n",
    "        version: the plugin version\n",
    "        inputs: a dictionary containing plugin inputs and settings\n",
    "        outputs: a dictionary containing plugin output types and settings\n",
    "        ui: a dictionary containing ui settings\n",
    "    \n",
    "    Class Methods:\n",
    "        all(): Returns a dictionary of all plugins, {plugin hash: WippPlugin object}\n",
    "        \n",
    "    Object Methods:\n",
    "        delete(): Delete the plugin from WIPP.\n",
    "        create(): Create the plugin in WIPP.\n",
    "    \"\"\"\n",
    "    _entry_point = 'plugins'\n",
    "    _data_type_name = 'Plugin'\n",
    "    _logger = logging.getLogger('wipp.Data.WippPlugin')\n",
    "\n",
    "    # Get the newest plugin that matches a plugin name\n",
    "    @classmethod\n",
    "    def get_by_name(cls,name,version=None):\n",
    "        cls._logger.info('get_by_name(): name={}, version={}'.format(name,version))\n",
    "        all_plugins = cls.all().values()\n",
    "        matching_plugins = [p for p in all_plugins if p.name==name]\n",
    "        \n",
    "        # If there are no matching plugins, throw an error\n",
    "        if len(matching_plugins)==0:\n",
    "            raise ValueError('No plugins match the supplied name: {}'.format(name))\n",
    "        \n",
    "        # If no version provided, get the latest version of the plugin\n",
    "        if version == None:\n",
    "            # If only one plugin matches, return that\n",
    "            if len(matching_plugins)==1:\n",
    "                return matching_plugins[0]\n",
    "            \n",
    "            version = [0,0,0] # major, minor, patch\n",
    "            \n",
    "            for p in reversed(matching_plugins):\n",
    "                c_ver = re.match(r\"([0-9]+).([0-9]+).([0-9]+)-?(.*)?\",p.version)\n",
    "                for i in range(3):\n",
    "                    v = version[i]\n",
    "                    c = c_ver.groups()[i]\n",
    "                    if int(c) > v:\n",
    "                        plugin = p\n",
    "                        version = [int(v) for v in p.version.split('.')]\n",
    "                        break\n",
    "                    elif int(c) < v:\n",
    "                        break\n",
    "        # Return specified version of plugin\n",
    "        else:\n",
    "            for p in reversed(matching_plugins):\n",
    "                if p.version==version:\n",
    "                    return p\n",
    "            # If the specified version could not be found, throw an error\n",
    "            raise ValueError('Version {} of plugin {} was not found in WIPP. Try installing it.'.format(version,name))\n",
    "            \n",
    "        return plugin\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'{self.name} (id: {self.id}, version: {self.version})'\n",
    "    \n",
    "    @classmethod\n",
    "    def all(cls):\n",
    "        return super().all(entry_point='plugins/')\n",
    "    \n",
    "    @classmethod\n",
    "    def install(cls,json):\n",
    "        cls._logger.info('install(): installing plugin...')\n",
    "        cls._logger.debug('install(): json={}'.format(json))\n",
    "        p = cls(data=json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "import numpy as np\n",
    "from aicssegmentation.core.visual import seg_fluo_side_by_side,  single_fluorescent_view, segmentation_quick_view\n",
    "from aicsimageio import AICSImage\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper\n",
    "from aicssegmentation.core.pre_processing_utils import intensity_normalization, image_smoothing_gaussian_3d\n",
    "from aicssegmentation.core.utils import get_middle_frame, hole_filling, get_3dseed_from_mid_frame\n",
    "from skimage.morphology import remove_small_objects, watershed, dilation, ball\n",
    "import json\n",
    "import markdown\n",
    "\n",
    "\n",
    "\n",
    "IMG = []\n",
    "segmented_images = []\n",
    "checkbox_dict = {}\n",
    "z_value_dict={}\n",
    "toggle_dict={}\n",
    "z_sliders = []\n",
    "image_list = []\n",
    "\n",
    "def get_selection_id(selection):\n",
    "    selection_id = re.match(r\".* \\(id: ([0-9A-Za-z]+).*\\)\",selection)\n",
    "    return selection_id.groups()[0]\n",
    "\n",
    "def fig2data ( fig ):\n",
    "    \"\"\" This function converts a matplotlib plot to an rbg image\n",
    "    \n",
    "    Input: \n",
    "        fig: matplotlib figure\n",
    "    Output:\n",
    "        data: rbg image for the input plot\n",
    "    \"\"\"    \n",
    "    \n",
    "    fig.canvas.draw ( )    \n",
    "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))  \n",
    "    return data\n",
    "\n",
    "def parse_list_string(list_str):\n",
    "    list_str = list_str.replace(' ', '')\n",
    "    list_str = list_str.replace('[','').replace(']','')\n",
    "    result_list = [ float(i) for i in list_str.split(',')]\n",
    "    return result_list\n",
    "\n",
    "def parse_nested_list_string(nested_str):\n",
    "\n",
    "    list_string = nested_str.replace(\" \",\"\")\n",
    "    list_string = list_string[1:-1].split('],[')\n",
    "    nested_list = []\n",
    "\n",
    "    for string in list_string:\n",
    "        temp_string = []\n",
    "        string = string.replace('[','').replace(']','')\n",
    "        temp_string = [ float(i) for i in string.split(',')]\n",
    "        nested_list.append(temp_string)\n",
    "    return nested_list\n",
    "\n",
    "\n",
    "def segment_image(image):\n",
    "    global metadata_textbox\n",
    "    \n",
    "    structure_channel = 0\n",
    "    struct_img0 = image[0,structure_channel,:,:,:].copy()\n",
    "\n",
    "    intensity_scaling_param = config_data['intensity_scaling_param']\n",
    "    struct_img = intensity_normalization(struct_img0, scaling_param=intensity_scaling_param) \n",
    "\n",
    "    gaussian_smoothing_sigma = config_data['gaussian_smoothing_sigma'] \n",
    "    structure_img_smooth = image_smoothing_gaussian_3d(struct_img, sigma=gaussian_smoothing_sigma)\n",
    "\n",
    "    middle_frame_method = config_data['middle_frame_method']\n",
    "    mid_z = get_middle_frame(structure_img_smooth, method=middle_frame_method)\n",
    "\n",
    "    f2_param = config_data['f2_param']\n",
    "    bw_mid_z = filament_2d_wrapper(structure_img_smooth[mid_z,:,:], f2_param)\n",
    "\n",
    "    hole_max = config_data['hole_max']\n",
    "    hole_min = config_data['hole_min']\n",
    "\n",
    "    bw_fill_mid_z = hole_filling(bw_mid_z, hole_min, hole_max)\n",
    "    seed = get_3dseed_from_mid_frame(np.logical_xor(bw_fill_mid_z, bw_mid_z), struct_img.shape, mid_z, hole_min)\n",
    "    bw_filled = watershed(struct_img, seed.astype(int), watershed_line=True)>0\n",
    "    seg = np.logical_xor(bw_filled, dilation(bw_filled, selem=ball(1)))\n",
    "\n",
    "    seg = seg > 0\n",
    "    out=seg.astype(np.uint8)\n",
    "    out[out>0]=255\n",
    "    return out        \n",
    "        \n",
    "    \n",
    "def display_img():\n",
    "    global img_display        \n",
    "    global checkbox_dict\n",
    "    global z_value_dict    \n",
    "    global IMG\n",
    "    \n",
    "    for key in checkbox_dict:\n",
    "        if checkbox_dict[key] == True:\n",
    "            index = key \n",
    "    z_index  = z_value_dict[index]\n",
    "    display_img = IMG[index][0,0,z_index,:,:]\n",
    "    display_img = np.interp(display_img,(np.min(display_img),np.max(display_img)), (0,1))*255       \n",
    "    img_display.value = cv2.imencode('.png', display_img)[1].tostring()\n",
    "    \n",
    "def display_segmented_img():\n",
    "    global seg_display\n",
    "    global segmented_images\n",
    "    global z_value_dict\n",
    "    global checkbox_dict    \n",
    "\n",
    "    for key in checkbox_dict:\n",
    "        if checkbox_dict[key] == True:\n",
    "            index = key     \n",
    "    z_index  = z_value_dict[index]\n",
    "    display_img = segmented_images[index][z_index,:,:]\n",
    "    display_img = np.interp(display_img,(np.min(display_img),np.max(display_img)), (0,1))*255       \n",
    "    seg_display.value = cv2.imencode('.png', display_img)[1].tostring()\n",
    "    \n",
    "    \n",
    "def update_segmentation(*args):\n",
    "    global IMG\n",
    "    global segmented_images\n",
    "    global metadata_textbox\n",
    "    global segment_button\n",
    "    \n",
    "    segment_button.disbaled = True\n",
    "    segment_button.description = 'Segmenting...'\n",
    " \n",
    "    \n",
    "    segmented_images = []\n",
    "    for index in range(len(IMG)):\n",
    "        img = segment_image(IMG[index])\n",
    "        segmented_images.append(img)\n",
    "        \n",
    "    segment_button.disbaled = False\n",
    "    segment_button.description = 'Segment'    \n",
    "    \n",
    "    display_segmented_img()\n",
    "    \n",
    "    \n",
    "def slider_callback(index):\n",
    "    def call_back(*args):\n",
    "        global z_value_dict\n",
    "        global metadata_textbox\n",
    "        global toggle_dict\n",
    "        #metadata_textbox.value = json.dumps(args[0], indent = 4)  \n",
    "        value = int(args[0]['new'])        \n",
    "        z_value_dict[index] = value\n",
    "        display_img()\n",
    "        display_segmented_img()         \n",
    "    return call_back\n",
    "\n",
    "\n",
    "def image_checkbox_observer():\n",
    "    \"\"\"\n",
    "    Call back function for the view_image check box widget. \n",
    "    It updates the check_box_dict when a user wants to \n",
    "    view/hide image.\n",
    "    \"\"\"\n",
    "    def call_back(*args):\n",
    "        global checkbox_dict\n",
    "        global toggle_dict\n",
    "        global metadata_textbox      \n",
    "         \n",
    "        # get_selection        \n",
    "        selection=args[0]['new']         \n",
    "        index = toggle_dict[selection]\n",
    "        #metadata_textbox.value = str(index)\n",
    "        \n",
    "        for key in checkbox_dict:\n",
    "            if key == index:\n",
    "                checkbox_dict[key] = True\n",
    "            else:\n",
    "                checkbox_dict[key] = False        \n",
    "        # update final image aray\n",
    "        display_img()\n",
    "        \n",
    "        display_segmented_img()  \n",
    "        metadata_textbox.value = 'great'\n",
    "    return call_back   \n",
    "   \n",
    "\n",
    "image_collection_path = ''\n",
    "def image_collection_observer(image_collections,images_widget):\n",
    "    \n",
    "    \"\"\"\n",
    "    call back function for the `select image collection` widget\n",
    "    \"\"\"\n",
    "    \n",
    "    def call_back(*args):\n",
    "        global image_collection_path\n",
    "        selection = get_selection_id(args[0]['new']) \n",
    "        image_collection_path = os.path.join('/opt/shared/wipp/collections', selection,'images')        \n",
    "        # enable widget to select image within that collection\n",
    "        images_widget.disabled=False\n",
    "        images_widget.options=os.listdir(image_collection_path)        \n",
    "        image_collections.value=args[0]['new']\n",
    "        image_collections.options=[str(ic) for ic in WippImageCollection.all().values()]        \n",
    "    return call_back \n",
    "\n",
    "\n",
    "def image_display_observer(index, z_slider):\n",
    "    def call_back(*args):\n",
    "        global image_collection_path\n",
    "        global img_display\n",
    "        global IMG\n",
    "        global out\n",
    "        global config_data\n",
    "        global seg_display\n",
    "        global z_value_dict\n",
    "        global toggle_dict\n",
    "        global segmented_images\n",
    "        global metadata_textbox\n",
    "        \n",
    "        FILE_NAME = os.path.join(image_collection_path, args[0]['new'])\n",
    "        reader = AICSImage(FILE_NAME) \n",
    "        IMG.append(reader.data.astype(np.float32)) \n",
    "        if index == 0:\n",
    "            checkbox_dict[index] = True\n",
    "        else:\n",
    "            checkbox_dict[index] = False\n",
    "        \n",
    "        toggle_dict['Image {}'.format(index+1)] = index\n",
    "            \n",
    "        if IMG[index].shape[2] > 1:\n",
    "            z_slider.disabled = False\n",
    "            depth = IMG[index].shape[2] - 1        \n",
    "            z_slider.max = depth   \n",
    "        z_value_dict[index] = 0       \n",
    "        display_img()       \n",
    "        segmented_images.append(segment_image(IMG[index]))\n",
    "        display_segmented_img()\n",
    "        \n",
    "    return call_back\n",
    "   \n",
    "\n",
    "def add_image(*args):\n",
    "    \n",
    "    global z_sliders\n",
    "    global select_image_panel\n",
    "    global image_selection_widget\n",
    "    \n",
    "    image_collections = widgets.Combobox(placeholder='Click on the box or start typing!',\n",
    "                                         options=[str(ic) for ic in WippImageCollection.all().values()],\n",
    "                                         description='Image Collections',\n",
    "                                         ensure_option=True,\n",
    "                                         disabled=False,\n",
    "                                         layout=widgets.Layout(width='95%'))\n",
    "\n",
    "    # widget to list images in the chosen image collection\n",
    "    images = widgets.Combobox(placeholder='Select an image collection first',\n",
    "                              options=[],\n",
    "                              description='Images',\n",
    "                              ensure_option=True,\n",
    "                              disabled=True,\n",
    "                              layout=widgets.Layout(width='95%'))\n",
    "\n",
    "    z_slider = widgets.FloatSlider(value=1,\n",
    "                                   min=0,\n",
    "                                   max=5,\n",
    "                                   step=1,\n",
    "                                   description=\"Z Position\",\n",
    "                                   continuous_update=False,\n",
    "                                   orientation='horizontal',\n",
    "                                   readout=False,\n",
    "                                   layout=widgets.Layout(width='68%'),\n",
    "                                   disabled=True)\n",
    "    \n",
    "    \n",
    "    z_sliders.append(z_slider)\n",
    "    image_selection_widget.options = image_selection_widget.options + ('Image {}'.format(len(select_image_panel.children)+1), )\n",
    "    #image_list.append(view_image)\n",
    "    \n",
    "    #link the widgets with their corresponding call back functions\n",
    "    image_collections.observe(image_collection_observer(image_collections,images),'value')\n",
    "    images.observe(image_display_observer(len(select_image_panel.children), z_slider), 'value')\n",
    "    z_slider.observe(slider_callback(len(select_image_panel.children)), 'value')\n",
    "    #view_image.observe(image_checkbox_observer(len(select_image_panel.children)),'value')\n",
    "    \n",
    "    # update the UI accordions\n",
    "    select_image_panel.children = select_image_panel.children + (widgets.VBox([image_collections,images,z_slider]),)\n",
    "    select_image_panel.set_title(len(select_image_panel.children) - 1,'Select Image {}'.format(len(select_image_panel.children)))\n",
    "    #image_list_panel.children = ((widgets.VBox(image_list),))\n",
    "\n",
    "def reset(*args):\n",
    "    global select_image_panel\n",
    "    global image_selection_widget\n",
    "    global IMG\n",
    "    global segmented_images\n",
    "    global checkbox_dict\n",
    "    global z_value_dict\n",
    "    global toggle_dict\n",
    "    global img_display\n",
    "    global seg_display\n",
    "    global metadata_textbox\n",
    "    global image_list_panel\n",
    "    \n",
    "\n",
    "    select_image_panel.children = []\n",
    "\n",
    "    IMG = []\n",
    "    segmented_images = []\n",
    "    checkbox_dict = {}\n",
    "    z_value_dict = {}\n",
    "    toggle_dict = {}\n",
    "    \n",
    "    img_display.value = cv2.imencode('.png', np.zeros((1024,1024)))[1].tostring()\n",
    "                              \n",
    "    seg_display.value = cv2.imencode('.png', np.zeros((1024,1024)))[1].tostring()\n",
    "\n",
    "    image_selection_widget = widgets.RadioButtons( options=[],                                               \n",
    "                                                   layout={'width': 'max-content'},\n",
    "                                                   description='Images:',\n",
    "                                                   disabled=False)\n",
    "    \n",
    "    image_list_panel.children = [image_selection_widget]\n",
    "    metadata_textbox.value = 'reset3'    \n",
    "    add_image()\n",
    "    image_selection_widget.observe(image_checkbox_observer(),'value')\n",
    "    \n",
    "    \n",
    "# initialize image display with a blank image\n",
    "img_display = widgets.Image( value=cv2.imencode('.png', np.zeros((1024,1024)))[1].tostring(),\n",
    "                           format='png',\n",
    "                           width=500,\n",
    "                           height=500)\n",
    "        \n",
    "seg_display = widgets.Image( value=cv2.imencode('.png', np.zeros((1024,1024)))[1].tostring(),\n",
    "                           format='png',\n",
    "                           width=500,\n",
    "                           height=500)     \n",
    "\n",
    "image_selection_widget = widgets.RadioButtons( options=[],                                               \n",
    "                                               layout={'width': 'max-content'},\n",
    "                                               description='Images:',\n",
    "                                               disabled=False)\n",
    "\n",
    "metadata_textbox= widgets.Textarea(value='Waiting to load image..',\n",
    "                                   placeholder='Type something',\n",
    "                                   description='String:',\n",
    "                                   disabled=False,\n",
    "                                   layout=widgets.Layout(width='300px',height='500px'))\n",
    "\n",
    "\n",
    "# ui accordions    \n",
    "select_image_panel = widgets.Accordion(children=[],\n",
    "                             description='Job inputs:')\n",
    "image_list_panel = widgets.Accordion(children=[image_selection_widget],\n",
    "                             description='Job inputs:')\n",
    "image_list_panel.set_title(0,'Image List')\n",
    "\n",
    "\n",
    "# add image button \n",
    "add_image()\n",
    "image_selection_widget.observe(image_checkbox_observer(),'value')\n",
    "add_image_button = widgets.Button(description='Add Image')\n",
    "add_image_button.on_click(add_image)\n",
    "reset_button = widgets.Button(description='Reset')\n",
    "reset_button.on_click(reset)\n",
    "AddImage_reset_buttons = widgets.HBox([add_image_button, reset_button])\n",
    "###############################################################################################\n",
    "\n",
    "config_data = {\n",
    "    \"workflow_name\": \"Playground_shell\",\n",
    "    \"intensity_scaling_param\": [\n",
    "        4000\n",
    "    ],\n",
    "    \"gaussian_smoothing_sigma\": 1,\n",
    "    \"middle_frame_method\": 'Intensity',\n",
    "    \"f2_param\": [\n",
    "        [\n",
    "            0.5,\n",
    "            0.01\n",
    "        ]\n",
    "    ],\n",
    "    \"hole_max\": 40000,\n",
    "    \"hole_min\": 400\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def param_observer(key):\n",
    "    def call_back(*args):\n",
    "        global config_data\n",
    "        global metadata_textbox\n",
    "        \n",
    "        if key == 'intensity':\n",
    "            config_data['intensity_scaling_param'] = parse_list_string(args[0]['new'])\n",
    "        elif key == 'gaussian_smoothing_sigma':\n",
    "            config_data['gaussian_smoothing_sigma'] = float(args[0]['new'])  \n",
    "        elif key == 'middle_frame_method':\n",
    "            config_data['middle_frame_method'] = args[0]['new']\n",
    "        elif key == 'f2_param':\n",
    "            config_data['f2_param'] = parse_nested_list_string(args[0]['new'])\n",
    "        elif key == 'hole_max':\n",
    "            config_data['hole_max'] = float(args[0]['new'])        \n",
    "        elif key == 'hole_min':\n",
    "            config_data['hole_min'] = float(args[0]['new'])           \n",
    "        json_object = json.dumps(config_data, indent = 4)\n",
    "        metadata_textbox.value = json_object           \n",
    "    \n",
    "    return call_back\n",
    "\n",
    "\n",
    "\n",
    "intensity_textbox = widgets.Textarea(value='[4000]',\n",
    "                                   placeholder='Type something',\n",
    "                                   description='Intensity:',\n",
    "                                   disabled=False,\n",
    "                                   layout=widgets.Layout(width='200px',height='30px'))\n",
    "\n",
    "gaussian_smoothing_sigma = widgets.FloatText( value=1,\n",
    "                                              description='Gaus. Sigma:', \n",
    "                                              layout=widgets.Layout(width='50%'),\n",
    "                                              disabled=False,\n",
    "                                              tooltip = 'Hello')\n",
    "\n",
    "middle_frame_method = widgets.RadioButtons(options=['intensity', 'z' ],\n",
    "                                     value='intensity', \n",
    "                                     description='middle_frame_method:',\n",
    "                                     disabled=False)\n",
    "\n",
    "f2_param_textbox= widgets.Textarea(value='[[0.5,0.01]]',\n",
    "                                   placeholder='Type something',\n",
    "                                   description='f2 param:',\n",
    "                                   disabled=False,\n",
    "                                   layout=widgets.Layout(width='300px',height='30px'))\n",
    "\n",
    "hole_max = widgets.FloatText( value=40000,\n",
    "                              description='hole_max:', \n",
    "                              layout=widgets.Layout(width='50%'),\n",
    "                              disabled=False)\n",
    "\n",
    "hole_min = widgets.FloatText( value=400,\n",
    "                              description='hole_min:', \n",
    "                              layout=widgets.Layout(width='50%'),\n",
    "                              disabled=False)\n",
    "\n",
    "#link to respective call_back functions\n",
    "intensity_textbox.observe(param_observer('intensity'), 'value')\n",
    "gaussian_smoothing_sigma.observe(param_observer('gaussian_smoothing_sigma'), 'value')\n",
    "f2_param_textbox.observe(param_observer('f2_param'), 'value')\n",
    "middle_frame_method.observe(param_observer('middle_frame_method'), 'value')\n",
    "hole_max.observe(param_observer('hole_max'), 'value')\n",
    "hole_min.observe(param_observer('hole_min'), 'value')\n",
    "\n",
    "#buttons\n",
    "segment_button = widgets.Button(description='Segment')\n",
    "segment_button.on_click(update_segmentation)\n",
    "save_config_button = widgets.Button(description='Save Config')\n",
    "buttons = widgets.HBox([segment_button, save_config_button])\n",
    "\n",
    "# user interface\n",
    "\n",
    "step1 = widgets.HTML(markdown.markdown(\"\"\"<h4>Step 1: Pre-Processing</h4>\"\"\"))\n",
    "step2 = widgets.HTML(markdown.markdown(\"\"\"<h4>Step 2: Core Algorithm</h4>\"\"\"))\n",
    "step3 = widgets.HTML(markdown.markdown(\"\"\"<h4>Step 3: Water Shed</h4>\"\"\"))\n",
    "param_box = widgets.VBox([step1, intensity_textbox, gaussian_smoothing_sigma, step2, middle_frame_method, f2_param_textbox, step3, hole_min, hole_max, buttons])\n",
    "parameter_panel= widgets.Accordion(children=[param_box],\n",
    "                             description='Parameters')\n",
    "parameter_panel.set_title(0,'Parameters')\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "title = widgets.HTML(markdown.markdown(\"\"\" <br><h1>Documentation</h1>\"\"\"))\n",
    "\n",
    "intro = widgets.HTML(markdown.markdown(\"\"\"   \n",
    "\n",
    "This notebook contains the workflows for lamin B1 (interphase-specific), and serves as a starting point for developing a classic segmentation workflow for your data with shell-like shapes.\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Cell Structure Observations:\n",
    "\n",
    "* [Lamin B1](https://www.allencell.org/cell-observations/category/lamin)\n",
    "\n",
    "----------------------------------------\n",
    "\n",
    "Key steps of the workflows:\n",
    "\n",
    "* Min-max intensity normalization / Auto-contrast\n",
    "* 3D Gaussian smoothing \n",
    "* 2D filament filter \n",
    "* watershed\n",
    "\n",
    "\n",
    " \"\"\"))\n",
    "\n",
    "step_1 = widgets.HTML(markdown.markdown(\"\"\" \n",
    "\n",
    "About selected algorithms and tuned parameters\n",
    "\n",
    "* **Intensity normalization**: Parameter `intensity_scaling_param` has two options: two values, say `[A, B]`, or single value, say `[K]`. For the first case, `A` and `B` are non-negative values indicating that the full intensity range of the stack will first be cut-off into **[mean - A * std, mean + B * std]** and then rescaled to **[0, 1]**. The smaller the values of `A` and `B` are, the higher the contrast will be. For the second case, `K`>0 indicates min-max Normalization with an absolute intensity upper bound `K` (i.e., anything above `K` will be chopped off and reset as the minimum intensity of the stack) and `K`=0 means min-max Normalization without any intensity bound.\n",
    "\n",
    "    * Parameter for Lamin B1 (interphase specific):  `intensity_scaling_param = [4000]`\n",
    "\n",
    "\n",
    "* **Smoothing** \n",
    "\n",
    "    3D gaussian smoothing with `gaussian_smoothing_sigma = 1`. The large the value is, the more the image will be smoothed.\n",
    "\n",
    "\n",
    " \"\"\"))\n",
    "\n",
    "\n",
    "\n",
    "step_2 = widgets.HTML(markdown.markdown(\"\"\"\n",
    "\n",
    "#### Apply 2d filament filter on the middle frame \n",
    "\n",
    "* **Part 1: get the middle frame**: We support two methods to get middle frame: `method='intensity'` and `method='z'`. `'intensity'` method assumes the number of foreground pixels (estimated by intensity) along z dimension has a unimodal distribution (such as Gaussian). Then, the middle frame is defined as the frame with peak of the distribution along z. `'z'` method simply return the middle z frame. \n",
    "\n",
    "    * Paramete for lamin b1 (interphase-specific):  `method='intensity'`\n",
    "\n",
    "\n",
    "* **Part 2: apply 2d filament filter on the middle frame**\n",
    "\n",
    "    * Parameter syntax: `[[scale_1, cutoff_1], [scale_2, cutoff_2], ....]` \n",
    "        * `scale_x` is set based on the estimated width of your target curvilinear shape. For example, if visually the width of the objects is usually 3~4 pixels, then you may want to set `scale_x` as `1` or something near `1` (like `1.25`). Multiple scales can be used, if you have objects of very different sizes.  \n",
    "        * `cutoff_x` is a threshold applied on the actual filter reponse to get the binary result. Smaller `cutoff_x` may yielf fatter segmentation, while larger `cutoff_x` could be less permisive and yield less objects and slimmer segmentation. \n",
    "    * Parameter for lamin b1 (interphase-specific):  `f2_param = [[0.5, 0.01]]`\n",
    "\n",
    "\n",
    "\"\"\"))\n",
    "\n",
    "step_3 = widgets.HTML(markdown.markdown(\"\"\" \n",
    " \n",
    "Apply watershed to get the shell:\n",
    "\n",
    "Parameters:\n",
    "  \n",
    "* hole_max = 40000\n",
    "* hole_min = 400\n",
    "\n",
    "\n",
    " \"\"\"))\n",
    "\n",
    "documentation_panel= widgets.Accordion(children=[intro, step_1, step_2, step_3 ],\n",
    "                             description='Documentation', selected_index=None )\n",
    "\n",
    "documentation_panel.set_title(0, 'Introduction:  Segmentation workflow for lamin b1 (interphase)')\n",
    "documentation_panel.set_title(1, 'Step 1: Pre-Processing')\n",
    "documentation_panel.set_title(2, 'Step 2: Core Algorithm')\n",
    "documentation_panel.set_title(3, 'Step 3: Water Shed ')\n",
    "\n",
    "#########################################################################################################################\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([widgets.VBox([select_image_panel, AddImage_reset_buttons, image_list_panel, parameter_panel]), img_display,seg_display]), title,documentation_panel]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
